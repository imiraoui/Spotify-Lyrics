{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics have on average: 2252 characters\n",
      "total chars: 55\n"
     ]
    }
   ],
   "source": [
    "df_songs = pd.read_csv(\"songs_details.csv\")\n",
    "df_english = df_songs[df_songs[\"lang_lyrics\"] == \"en\"]\n",
    "print(\"Lyrics have on average:\",int(df_english[\"lyrics_cleaned\"].apply(lambda x: len(x)).mean()), \"characters\")\n",
    "\n",
    "texts = \"\"\n",
    "for song in df_english.index:\n",
    "    lyrics = df_english.loc[song,\"lyrics_cleaned\"]\n",
    "    texts = str(lyrics) + texts\n",
    "    \n",
    "chars = sorted(list(set(texts)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 223749 \n",
      "\n",
      "[' uh fuck i dont fuck with you you little', ' fuck i dont fuck with you you little st', 'ck i dont fuck with you you little stupi', 'i dont fuck with you you little stupid a', 'ont fuck with you you little stupid ass ', ' fuck with you you little stupid ass bit', 'ck with you you little stupid ass bitch ', 'with you you little stupid ass bitch i a', 'h you you little stupid ass bitch i aint', 'ou you little stupid ass bitch i aint fu'] \n",
      "\n",
      "[' ', 'u', 'd', 's', 'b', 'c', 'i', 'i', ' ', 'c']\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(texts) - maxlen, step):\n",
    "    sentences.append(texts[i: i + maxlen])\n",
    "    next_chars.append(texts[i + maxlen])\n",
    "print('Number of sequences:', len(sentences), \"\\n\")\n",
    "\n",
    "print(sentences[:10], \"\\n\")\n",
    "print(next_chars[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/iliasmiraoui/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked for specified epochs. Prints generated text.\n",
    "    # Using epoch+1 to be consistent with the training epochs printed by Keras\n",
    "    if epoch+1 == 1 or epoch+1 == 15:\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(texts) - maxlen - 1)\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = texts[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()\n",
    "    else:\n",
    "        print()\n",
    "        print('----- Not generating text after Epoch: %d' % epoch)\n",
    "\n",
    "generate_text = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/iliasmiraoui/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      " - 94s - loss: 1.8473\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"t you try again boy you gotta do it righ\"\n",
      "t you try again boy you gotta do it right in the might and i cant they want the might the mind me i cant the might me i know i cant the mind i talkin and i still the mind i know me i not a mind i cant the might i cant thing i think im think i talk the mind i aint man the mind i think im think im the mind this the stare the mind i know i still the mind i cant thinking i aint that i cant gotta the mind mind me i cant they thinking in the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"t you try again boy you gotta do it righ\"\n",
      "t you try again boy you gotta do it right go to me san me nothin give up pay out these going im all nate i how the man the mind that and me i cant this she in the might a give up and im truight girl and prop i that misting they will in to im like come im say the money thats brather when the mind be fitted in the mind man a hunds that im gome and be cause im tome out i want the might i know me sing man hold up in the the mifd like me bab\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"t you try again boy you gotta do it righ\"\n",
      "t you try again boy you gotta do it right of this just with uncout undasocs fife mabeds with ah a bitch i can i lant beut yeah how get me shart move back gettuh bitch fixted dont firl intide lea a hundt oh ever they nabnih hit a nieving the lix buasi the badenta i make i dick man riun that nut anttor give like anybody ats up id hamb start bagainted niggt sinkin mam pedping on rauted astin my hight no i reulen bebound lifey im just give \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"t you try again boy you gotta do it righ\"\n",
      "t you try again boy you gotta do it rights in that aims came thats doothe im lilion take yah straight i fude nowh but lotime is okers nah golder like yolver a jabe ive bealy tepip thingi pla seestser i jeabtin ontem tiliin we see you gaintoo pasise stonna casted better dighn bay piah hollug aye your san and just niggam put it rouped me i dinaustii nigga juet zit but ig hus1 no new dont be take real wai dont gincj with the trookes creenp\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.84731, saving model to weights.hdf5\n",
      "Epoch 2/15\n",
      " - 87s - loss: 1.5675\n",
      "\n",
      "----- Not generating text after Epoch: 1\n",
      "\n",
      "Epoch 00002: loss improved from 1.84731 to 1.56752, saving model to weights.hdf5\n",
      "Epoch 3/15\n",
      " - 86s - loss: 1.4886\n",
      "\n",
      "----- Not generating text after Epoch: 2\n",
      "\n",
      "Epoch 00003: loss improved from 1.56752 to 1.48857, saving model to weights.hdf5\n",
      "Epoch 4/15\n",
      " - 89s - loss: 1.4479\n",
      "\n",
      "----- Not generating text after Epoch: 3\n",
      "\n",
      "Epoch 00004: loss improved from 1.48857 to 1.44793, saving model to weights.hdf5\n",
      "Epoch 5/15\n",
      " - 89s - loss: 1.4214\n",
      "\n",
      "----- Not generating text after Epoch: 4\n",
      "\n",
      "Epoch 00005: loss improved from 1.44793 to 1.42137, saving model to weights.hdf5\n",
      "Epoch 6/15\n",
      " - 88s - loss: 1.4011\n",
      "\n",
      "----- Not generating text after Epoch: 5\n",
      "\n",
      "Epoch 00006: loss improved from 1.42137 to 1.40112, saving model to weights.hdf5\n",
      "Epoch 7/15\n",
      " - 88s - loss: 1.3909\n",
      "\n",
      "----- Not generating text after Epoch: 6\n",
      "\n",
      "Epoch 00007: loss improved from 1.40112 to 1.39089, saving model to weights.hdf5\n",
      "Epoch 8/15\n",
      " - 88s - loss: 1.3817\n",
      "\n",
      "----- Not generating text after Epoch: 7\n",
      "\n",
      "Epoch 00008: loss improved from 1.39089 to 1.38174, saving model to weights.hdf5\n",
      "Epoch 9/15\n",
      " - 89s - loss: 1.3721\n",
      "\n",
      "----- Not generating text after Epoch: 8\n",
      "\n",
      "Epoch 00009: loss improved from 1.38174 to 1.37210, saving model to weights.hdf5\n",
      "Epoch 10/15\n",
      " - 89s - loss: 1.3727\n",
      "\n",
      "----- Not generating text after Epoch: 9\n",
      "\n",
      "Epoch 00010: loss did not improve from 1.37210\n",
      "Epoch 11/15\n",
      " - 87s - loss: 1.3782\n",
      "\n",
      "----- Not generating text after Epoch: 10\n",
      "\n",
      "Epoch 00011: loss did not improve from 1.37210\n",
      "Epoch 12/15\n",
      " - 88s - loss: 1.4429\n",
      "\n",
      "----- Not generating text after Epoch: 11\n",
      "\n",
      "Epoch 00012: loss did not improve from 1.37210\n",
      "Epoch 13/15\n",
      " - 88s - loss: 2.0592\n",
      "\n",
      "----- Not generating text after Epoch: 12\n",
      "\n",
      "Epoch 00013: loss did not improve from 1.37210\n",
      "Epoch 14/15\n",
      " - 90s - loss: 5.7323\n",
      "\n",
      "----- Not generating text after Epoch: 13\n",
      "\n",
      "Epoch 00014: loss did not improve from 1.37210\n",
      "Epoch 15/15\n",
      " - 95s - loss: 4.1438\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" but i feel it still ooh woo ooh woo but\"\n",
      " but i feel it still ooh woo ooh woo but  he de  the t wh me  me t mn i "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iliasmiraoui/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qo be wju   ke s t zt th t  me thre the sout  nin thek i  i the me droceui git i goe me the jume ige cn i  anij sz   ca t  cl e t h foren chtim the  ther c me kult ou bu fe th the i i snve the s juju thegh  th  de jung i th i me he t th  wahe th u w t qu te thuc  therar  he xe fot h m th nhe a khe t i go   bet  we thad aj a y i ke tum nea conl y ux tjut tht up   ck \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" but i feel it still ooh woo ooh woo but\"\n",
      " but i feel it still ooh woo ooh woo but  he ded inl ro lhd d me nut s l the h re wh nv  ea th0ee  i  ingr i p  utj th nort up an reexec st jun mi ce me ye silgot in p in the  h  wh do in  gou i  squd t the ande tung he toki y they eem wi ssast m te ferd me ir conge t lei s g ano in the jut i  the   withe you jut i p me  th m  hex  mes my al caithe minde helufue m n a atheat ade y a me theyejx nea i swe  as tar g men romr oj s iuc s tx \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" but i feel it still ooh woo ooh woo but\"\n",
      " but i feel it still ooh woo ooh woo butey agat it i s meit im roy tr tigho e sele  er hao y lor rheomutont as daxir hale in ime th t t s sit illo jyyt y eryih ge od taa rhae ltti h  yeunslon ll heh s d a ttherluanal dr ianoum yissadsoume  e sh ay up e ss ingenhi norr tjosth taitinorodon dore yestaim  ve re l yrad we uy h n d thlsti tolllu risr ai ies was  itherir upys opc upeaz rw sez o inilel ig ih ist sanryalun ldbiqu  te ngef thinla\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" but i feel it still ooh woo ooh woo but\"\n",
      " but i feel it still ooh woo ooh woo butl taelon nin  upede aude hi  plyoollim icai de th har senih oe  th li duy  nits tiionsme l ben srer hore alaior hr hlodan o omnery nalstyy se  metheineh otoued  ih out l t aoh st ude s ghet i ge  y is cey ohya nom o a up t soatezottiattsie e thar somhoneyoupy uneomy s  n mo  roto the lu  upcy t the ouheyo myree etat  lim e syju igo whrah yi m  uhat lez lta eung imdn snpisqreetst i gi ginesoclitet \n",
      "\n",
      "Epoch 00015: loss did not improve from 1.37210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2d377fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the checkpoint\n",
    "filepath = \"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              callbacks=[generate_text, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
